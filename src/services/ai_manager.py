#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - AI Manager com Sistema de Fallback
Gerenciador inteligente de m√∫ltiplas IAs com fallback autom√°tico
"""

import os
import logging
import time
import json
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import google.generativeai as genai
import openai
import requests

logger = logging.getLogger(__name__)

class AIManager:
    """Gerenciador de IAs com sistema de fallback autom√°tico"""
    
    def __init__(self):
        """Inicializa o gerenciador de IAs"""
        self.providers = {
            'gemini': {
                'client': None,
                'available': False,
                'priority': 1,
                'rate_limit_reset': None,
                'error_count': 0,
                'model': 'gemini-1.5-flash'  # Modelo mais eficiente
            },
            'openai': {
                'client': None,
                'available': False,
                'priority': 2,
                'rate_limit_reset': None,
                'error_count': 0,
                'model': 'gpt-3.5-turbo'  # Modelo mais est√°vel
            },
            'huggingface': {
                'client': None,
                'available': False,
                'priority': 3,
                'rate_limit_reset': None,
                'error_count': 0,
                'models': [
                    "microsoft/DialoGPT-medium",
                    "microsoft/DialoGPT-large",
                    "facebook/blenderbot-400M-distill",
                    "google/flan-t5-base",
                    "HuggingFaceH4/zephyr-7b-beta"
                ],
                'current_model_index': 0
            }
        }
        
        self.initialize_providers()
        logger.info(f"AI Manager inicializado com {len([p for p in self.providers.values() if p['available']])} provedores dispon√≠veis")
    
    def initialize_providers(self):
        """Inicializa todos os provedores de IA"""
        
        # Inicializa Gemini
        try:
            gemini_key = os.getenv('GEMINI_API_KEY')
            if gemini_key:
                genai.configure(api_key=gemini_key)
                self.providers['gemini']['client'] = genai.GenerativeModel("gemini-1.5-flash")
                self.providers['gemini']['available'] = True
                logger.info("‚úÖ Gemini Flash inicializado com sucesso")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Falha ao inicializar Gemini: {str(e)}")
        
        # Inicializa OpenAI
        try:
            openai_key = os.getenv('OPENAI_API_KEY')
            if openai_key:
                openai.api_key = openai_key
                self.providers["openai"]["client"] = openai.OpenAI(api_key=openai_key)
                self.providers["openai"]["available"] = True
                logger.info("‚úÖ OpenAI inicializado com sucesso")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Falha ao inicializar OpenAI: {str(e)}")
        
        # Inicializa HuggingFace
        try:
            hf_key = os.getenv('HUGGINGFACE_API_KEY')
            if hf_key:
                self.providers['huggingface']['client'] = {
                    'api_key': hf_key,
                    'base_url': 'https://api-inference.huggingface.co/models/'
                }
                self.providers['huggingface']['available'] = True
                logger.info("‚úÖ HuggingFace inicializado com sucesso")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Falha ao inicializar HuggingFace: {str(e)}")
    
    def get_best_provider(self) -> Optional[str]:
        """Retorna o melhor provedor dispon√≠vel"""
        available_providers = [
            (name, provider) for name, provider in self.providers.items() 
            if provider['available'] and provider['error_count'] < 5
        ]
        
        if not available_providers:
            # Reset error counts se todos falharam
            for provider in self.providers.values():
                provider['error_count'] = 0
            available_providers = [
                (name, provider) for name, provider in self.providers.items() 
                if provider['available']
            ]
        
        if available_providers:
            # Ordena por prioridade e menor n√∫mero de erros
            available_providers.sort(key=lambda x: (x[1]['priority'], x[1]['error_count']))
            return available_providers[0][0]
        
        return None
    
    def generate_analysis(self, prompt: str, max_tokens: int = 8192) -> Optional[str]:
        """Gera an√°lise usando o melhor provedor dispon√≠vel"""
        
        provider_name = self.get_best_provider()
        if not provider_name:
            logger.error("‚ùå Nenhum provedor de IA dispon√≠vel")
            return None
        
        logger.info(f"ü§ñ Usando provedor: {provider_name}")
        
        try:
            if provider_name == 'gemini':
                return self._generate_with_gemini(prompt, max_tokens)
            elif provider_name == 'openai':
                return self._generate_with_openai(prompt, max_tokens)
            elif provider_name == 'huggingface':
                return self._generate_with_huggingface(prompt, max_tokens)
        except Exception as e:
            logger.error(f"‚ùå Erro no provedor {provider_name}: {str(e)}")
            self.providers[provider_name]['error_count'] += 1
            
            # Tenta pr√≥ximo provedor
            return self._try_fallback(prompt, max_tokens, exclude=[provider_name])
        
        return None
    
    def _generate_with_gemini(self, prompt: str, max_tokens: int) -> Optional[str]:
        """Gera conte√∫do usando Gemini"""
        try:
            client = self.providers['gemini']['client']
            
            generation_config = {
                'temperature': 0.7,
                'top_p': 0.95,
                'top_k': 64,
                'max_output_tokens': min(max_tokens, 2048),  # Reduz para evitar quota
                'candidate_count': 1
            }
            
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            ]
            
            response = client.generate_content(
                prompt,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            if response.text:
                logger.info(f"‚úÖ Gemini gerou {len(response.text)} caracteres")
                return response.text
            else:
                raise Exception("Resposta vazia do Gemini")
                
        except Exception as e:
            if "quota" in str(e).lower() or "limit" in str(e).lower():
                logger.warning(f"‚ö†Ô∏è Gemini atingiu limite de quota: {str(e)}")
                self.providers['gemini']['rate_limit_reset'] = time.time() + 3600  # 1 hora
            raise e
    
    def _generate_with_openai(self, prompt: str, max_tokens: int) -> Optional[str]:
        """Gera conte√∫do usando OpenAI"""
        try:
            openai_key = os.getenv("OPENAI_API_KEY")
            if not openai_key:
                raise ValueError("OPENAI_API_KEY not found")
            client = openai.OpenAI(api_key=openai_key)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em an√°lise de mercado ultra-detalhada."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=min(max_tokens, 1500),
                temperature=0.7,
                top_p=0.95
            )
            
            content = response.choices[0].message.content
            if content:
                logger.info(f"‚úÖ OpenAI gerou {len(content)} caracteres")
                return content
            else:
                raise Exception("Resposta vazia do OpenAI")
                
        except Exception as e:
            if "quota" in str(e).lower() or "limit" in str(e).lower():
                logger.warning(f"‚ö†Ô∏è OpenAI atingiu limite de quota: {str(e)}")
                self.providers['openai']['rate_limit_reset'] = time.time() + 3600
            raise e
    
    def _generate_with_huggingface(self, prompt: str, max_tokens: int) -> Optional[str]:
        """Gera conte√∫do usando HuggingFace com rota√ß√£o de modelos"""
        hf_config = self.providers['huggingface']
        models = hf_config['models']
        
        # Tenta todos os modelos dispon√≠veis
        for attempt in range(len(models)):
            current_model = models[hf_config['current_model_index']]
            
            try:
                url = f"{hf_config['client']['base_url']}{current_model}"
                headers = {
                    "Authorization": f"Bearer {hf_config['client']['api_key']}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": max_tokens,
                        "temperature": 0.9,
                        "return_full_text": False,
                        "do_sample": True,
                        "top_p": 0.95
                    },
                    "options": {
                        "wait_for_model": True,
                        "use_cache": False
                    }
                }
                
                response = requests.post(url, headers=headers, json=payload, timeout=60)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if isinstance(data, list) and len(data) > 0:
                        if "generated_text" in data[0]:
                            content = data[0]["generated_text"]
                        elif "text" in data[0]:
                            content = data[0]["text"]
                        else:
                            content = str(data[0])
                        
                        # Remove prompt se inclu√≠do
                        if content.startswith(prompt):
                            content = content[len(prompt):].strip()
                        
                        if content:
                            logger.info(f"‚úÖ HuggingFace ({current_model}) gerou {len(content)} caracteres")
                            return content
                
                elif response.status_code == 503:
                    logger.warning(f"‚ö†Ô∏è Modelo {current_model} carregando, tentando pr√≥ximo...")
                    # Rotaciona para pr√≥ximo modelo
                    hf_config['current_model_index'] = (hf_config['current_model_index'] + 1) % len(models)
                    continue
                else:
                    logger.warning(f"‚ö†Ô∏è Erro {response.status_code} no modelo {current_model}")
                    hf_config['current_model_index'] = (hf_config['current_model_index'] + 1) % len(models)
                    continue
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro no modelo {current_model}: {str(e)}")
                hf_config['current_model_index'] = (hf_config['current_model_index'] + 1) % len(models)
                continue
        
        raise Exception("Todos os modelos HuggingFace falharam")
    
    def _try_fallback(self, prompt: str, max_tokens: int, exclude: List[str] = None) -> Optional[str]:
        """Tenta usar provedor de fallback"""
        exclude = exclude or []
        
        for provider_name in ['gemini', 'openai', 'huggingface']:
            if provider_name in exclude:
                continue
                
            if not self.providers[provider_name]['available']:
                continue
                
            if self.providers[provider_name]['error_count'] >= 5:
                continue
            
            logger.info(f"üîÑ Tentando fallback para: {provider_name}")
            
            try:
                if provider_name == 'gemini':
                    return self._generate_with_gemini(prompt, max_tokens)
                elif provider_name == 'openai':
                    return self._generate_with_openai(prompt, max_tokens)
                elif provider_name == 'huggingface':
                    return self._generate_with_huggingface(prompt, max_tokens)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Fallback {provider_name} falhou: {str(e)}")
                self.providers[provider_name]['error_count'] += 1
                continue
        
        logger.error("‚ùå Todos os provedores de fallback falharam")
        return None
    
    def get_provider_status(self) -> Dict[str, Any]:
        """Retorna status de todos os provedores"""
        status = {}
        
        for name, provider in self.providers.items():
            status[name] = {
                'available': provider['available'],
                'priority': provider['priority'],
                'error_count': provider['error_count'],
                'rate_limited': (provider.get('rate_limit_reset') or 0) > time.time()
            }
            
            if name == 'huggingface' and provider['available']:
                status[name]['current_model'] = provider['models'][provider['current_model_index']]
                status[name]['available_models'] = len(provider['models'])
        
        return status
    
    def reset_provider_errors(self, provider_name: str = None):
        """Reset contadores de erro"""
        if provider_name:
            if provider_name in self.providers:
                self.providers[provider_name]['error_count'] = 0
                logger.info(f"üîÑ Reset erros do provedor: {provider_name}")
        else:
            for provider in self.providers.values():
                provider['error_count'] = 0
            logger.info("üîÑ Reset erros de todos os provedores")

# Inst√¢ncia global
ai_manager = AIManager()
